{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq_sum.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNScAkjgQ6r0qmbfRVptdrE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s-wx20PR2yRU","colab_type":"text"},"source":["# 足し算をSeq2Seqで学習"]},{"cell_type":"code","metadata":{"id":"ikeiwpeu2OK7","colab_type":"code","colab":{}},"source":["# 辞書の作成\n","word2id = {str(i): i for i in range(10)}\n","# <pad>:パディング, <eos>:終了文字\n","word2id.update({\"<pad>\": 10, \"+\": 11, \"<eos>\": 12})\n","id2word = {v: k for k, v in word2id.items()}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j7DDIAzz2dFY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"f3437a57-36ba-4e25-8a79-4bacf6cb97b7","executionInfo":{"status":"ok","timestamp":1582206526806,"user_tz":-540,"elapsed":878,"user":{"displayName":"笛木正雄","photoUrl":"","userId":"16173190851009711320"}}},"source":["word2id"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'+': 11,\n"," '0': 0,\n"," '1': 1,\n"," '2': 2,\n"," '3': 3,\n"," '4': 4,\n"," '5': 5,\n"," '6': 6,\n"," '7': 7,\n"," '8': 8,\n"," '9': 9,\n"," '<eos>': 12,\n"," '<pad>': 10}"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"nS19HyVg26GJ","colab_type":"code","colab":{}},"source":["import random\n","from sklearn.model_selection import train_test_split\n","\n","def load_dataset(N=20000):\n","    def generate_number():\n","        number = [random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] \n","        # a <= N <= b random.randint(a, b)\n","        return int(\"\".join(number))\n","    \n","    def padding(string, training=True):\n","        string = \"{:*<7s}\".format(string) if training else \"{:*<6s}\".format(string)\n","        return string.replace(\"*\", \"<pad>\")\n","    \n","    # 辞書を使ってidに変換\n","    def transform(string, seq_len=7):\n","        tmp = []\n","        for i, c in enumerate(string):\n","            try:\n","                tmp.append(word2id[c])\n","            except:\n","                tmp += [word2id[\"<pad>\"]] * (seq_len - i)\n","                break\n","        return tmp\n","    data = []\n","    target = []    \n","    for _ in range(N):\n","        x = generate_number()\n","        y = generate_number()\n","        z = x + y\n","        left = padding(str(x) + \"+\" + str(y))\n","        right = padding(str(z), training=False)\n","        data.append(transform(left))\n","        right = transform(right, seq_len=6)\n","        # <eos>スタート\n","        right = [12] + right[:5]\n","        right[right.index(10)] = 12\n","        target.append(right)\n","        \n","    return data, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJD2RYZuBzTJ","colab_type":"code","colab":{}},"source":["# 学習データの作成\n","data, target = load_dataset()\n","train_x, test_x, train_t, test_t = train_test_split(data, target, test_size=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tiQPZypeJCuU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"32dc3237-d849-4989-b122-be3575ddfff5","executionInfo":{"status":"ok","timestamp":1582211316799,"user_tz":-540,"elapsed":925,"user":{"displayName":"笛木正雄","photoUrl":"","userId":"16173190851009711320"}}},"source":["train_x[0], train_t[0]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["([1, 11, 3, 10, 10, 10, 10], [12, 4, 12, 10, 10, 10])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"O4t3EfFECICx","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","\n","embedding_dim = 16\n","hidden_dim = 128\n","vocab_size = len(word2id)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","class Encoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n","        super(Encoder, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.batch_size = batch_size\n","\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","\n","    def forward(self, indices):\n","        embedding = self.word_embeddings(indices)\n","        if embedding.dim() == 2:\n","            embedding = torch.unsqueeze(embedding, 1)\n","        _, state = self.gru(embedding, torch.zeros(1, self.batch_size, self.hidden_dim, device=device))\n","        \n","        return state\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n","        super(Decoder, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.batch_size = batch_size\n","\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n","        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n","        self.output = nn.Linear(hidden_dim, vocab_size)\n","\n","    def forward(self, index, state):\n","        embedding = self.word_embeddings(index)\n","        if embedding.dim() == 2:\n","            embedding = torch.unsqueeze(embedding, 1)\n","        gruout, state = self.gru(embedding, state)\n","        output = self.output(gruout)\n","        return output, state\n","\n","\n","encoder = Encoder(vocab_size, embedding_dim, hidden_dim).to(device)\n","decoder = Decoder(vocab_size, embedding_dim, hidden_dim).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=word2id[\"<pad>\"])\n","\n","# Initialize opotimizers\n","encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n","decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_n7YmdTcCQoH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"outputId":"d40c9012-b745-4d85-8ec4-0a1c20e2f2a6","executionInfo":{"status":"ok","timestamp":1582210715628,"user_tz":-540,"elapsed":502878,"user":{"displayName":"笛木正雄","photoUrl":"","userId":"16173190851009711320"}}},"source":["from datetime import datetime\n","from sklearn.utils import shuffle\n","\n","batch_size=100\n","def train2batch(data, target, batch_size=100):\n","    input_batch = []\n","    output_batch = []\n","    data, target = shuffle(data, target)\n","    \n","    for i in range(0, len(data), batch_size):\n","        input_tmp = []\n","        output_tmp = []\n","        for j in range(i, i+batch_size):\n","            input_tmp.append(data[j])\n","            output_tmp.append(target[j])\n","        input_batch.append(input_tmp)\n","        output_batch.append(output_tmp)\n","    return input_batch, output_batch\n","\n","def get_current_time():\n","    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","\n","print(\"Training...\")\n","n_epoch = 100\n","for epoch in range(1, n_epoch+1):\n","    input_batch, output_batch = train2batch(train_x, train_t)\n","    for i in range(len(input_batch)):\n","        # Zero gradients\n","        encoder_optimizer.zero_grad()\n","        decoder_optimizer.zero_grad()\n","        # Prepare tensor\n","        inputs = torch.tensor(input_batch[i], device=device)\n","        outputs = torch.tensor(output_batch[i], device=device)\n","        # Forward pass through encoder\n","        encoder_hidden = encoder(inputs)\n","        # Create source and target\n","        source = outputs[:, :-1]\n","        target = outputs[:, 1:]\n","        decoder_hidden = encoder_hidden\n","        \n","        # Forward batch of sequences through decoder one time step at a time\n","        loss = 0\n","        for i in range(source.size(1)):\n","            decoder_output, decoder_hidden = decoder(source[:, i], decoder_hidden)\n","            decoder_output = torch.squeeze(decoder_output)\n","            loss += criterion(decoder_output, target[:, i])\n","\n","        # Perform backpropagation\n","        loss.backward()\n","        \n","        # Adjust model weights\n","        encoder_optimizer.step()\n","        decoder_optimizer.step()\n","    \n","    if epoch % 10 == 0:\n","        print(get_current_time(), \"Epoch %d: %.2f\" % (epoch, loss.item()))        \n","        \n","    if epoch % 10 == 0:\n","        model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n","        torch.save({\n","            'encoder_model': encoder.state_dict(),\n","            'decoder_model': decoder.state_dict(),\n","        }, model_name)\n","        print(\"Saving the checkpoint...\")"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Training...\n","2020-02-20 14:51:03 Epoch 10: 3.06\n","Saving the checkpoint...\n","2020-02-20 14:51:54 Epoch 20: 1.96\n","Saving the checkpoint...\n","2020-02-20 14:52:43 Epoch 30: 1.36\n","Saving the checkpoint...\n","2020-02-20 14:53:33 Epoch 40: 1.01\n","Saving the checkpoint...\n","2020-02-20 14:54:23 Epoch 50: 0.87\n","Saving the checkpoint...\n","2020-02-20 14:55:13 Epoch 60: 0.31\n","Saving the checkpoint...\n","2020-02-20 14:56:03 Epoch 70: 0.26\n","Saving the checkpoint...\n","2020-02-20 14:56:53 Epoch 80: 0.09\n","Saving the checkpoint...\n","2020-02-20 14:57:43 Epoch 90: 0.06\n","Saving the checkpoint...\n","2020-02-20 14:58:34 Epoch 100: 0.04\n","Saving the checkpoint...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WrP6tgG6E-MX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}